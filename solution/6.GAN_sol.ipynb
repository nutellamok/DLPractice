{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"4.GAN_sol.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"qcMu8aQGvs8d"},"source":["## Download necessary libraries "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"rkvnrzXgvs8f","colab":{}},"source":["from __future__ import print_function\n","#%matplotlib inline\n","import argparse\n","import os\n","import zipfile\n","import random\n","import torch\n","import torch.nn as nn\n","import torch.nn.parallel\n","import torch.backends.cudnn as cudnn\n","import torch.optim as optim\n","import torch.utils.data\n","import torchvision.datasets as dset\n","import torchvision.transforms as transforms\n","import torchvision.utils as vutils\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib.animation as animation\n","from IPython.display import HTML"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TbohiiX0YGsG","colab_type":"text"},"source":["## Download celebA dataset"]},{"cell_type":"code","metadata":{"id":"prVOfGGycXjR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":221},"outputId":"9fad1d67-3706-474d-9109-250dcffc5e7d","executionInfo":{"status":"ok","timestamp":1582673861990,"user_tz":-540,"elapsed":101250,"user":{"displayName":"Jenny Mok","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBx6WjQhn61jI2o2RUoma2WrRvQIP2K7I8ROHvF7A=s64","userId":"14608516416463645410"}}},"source":["!mkdir data_faces && wget https://s3-us-west-1.amazonaws.com/udacity-dlnfd/datasets/celeba.zip \n","\n","with zipfile.ZipFile(\"celeba.zip\",\"r\") as zip_ref:\n","  zip_ref.extractall(\"data_faces/\")\n","\n","dataDir = 'data_faces/img_align_celeba'\n","img_list = os.listdir(dataDir)\n","print(len(img_list))"],"execution_count":2,"outputs":[{"output_type":"stream","text":["--2020-02-25 23:35:56--  https://s3-us-west-1.amazonaws.com/udacity-dlnfd/datasets/celeba.zip\n","Resolving s3-us-west-1.amazonaws.com (s3-us-west-1.amazonaws.com)... 52.219.120.8\n","Connecting to s3-us-west-1.amazonaws.com (s3-us-west-1.amazonaws.com)|52.219.120.8|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1443490838 (1.3G) [application/zip]\n","Saving to: ‘celeba.zip’\n","\n","celeba.zip          100%[===================>]   1.34G  21.1MB/s    in 67s     \n","\n","2020-02-25 23:37:09 (20.6 MB/s) - ‘celeba.zip’ saved [1443490838/1443490838]\n","\n","202599\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"HqTx0go1vs8n","colab":{}},"source":["# Create the dataset\n","dataset = dset.ImageFolder(root='./data_faces',\n","                           transform=transforms.Compose([\n","                               transforms.Resize(64),\n","                               transforms.CenterCrop(64),\n","                               transforms.ToTensor(),\n","                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n","                           ]))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vTfWzD-WYLv5","colab_type":"text"},"source":["## Useful variable definitions are provided"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"sgLYHm0-vs8j","colab":{}},"source":["# Number of channels in the training images. For color images this is 3\n","nc = 3\n","# Size of z latent vector (i.e. size of generator input)\n","nz = 100\n","# size of feature maps in generator\n","ngf = 64\n","# Size of feature maps in discriminator\n","ndf = 64"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"zK1E46ppvs8p"},"source":["## Implement generator & discriminator\n","\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"zcFdaEZ4vs8t","colab":{}},"source":["class Generator(nn.Module):\n","    def __init__(self):\n","        super(Generator, self).__init__()\n","        self.main = nn.Sequential(\n","            # input is Z, going into a convolution\n","            nn.ConvTranspose2d( nz, ngf * 8, 4, 1, 0, bias=False),\n","            nn.BatchNorm2d(ngf * 8),\n","            nn.ReLU(True),\n","            # state size. (ngf*8) x 4 x 4\n","            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(ngf * 4),\n","            nn.ReLU(True),\n","            # state size. (ngf*4) x 8 x 8\n","            nn.ConvTranspose2d( ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(ngf * 2),\n","            nn.ReLU(True),\n","            # state size. (ngf*2) x 16 x 16\n","            nn.ConvTranspose2d( ngf * 2, ngf, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(ngf),\n","            nn.ReLU(True),\n","            # state size. (ngf) x 32 x 32\n","            nn.ConvTranspose2d( ngf, nc, 4, 2, 1, bias=False),\n","            nn.Tanh()\n","            # state size. (nc) x 64 x 64\n","        )\n","\n","    def forward(self, input):\n","        return self.main(input)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"gLwfT-kovs8w","colab":{}},"source":["class Discriminator(nn.Module):\n","    def __init__(self):\n","        super(Discriminator, self).__init__()\n","        self.main = nn.Sequential(\n","            # input is (nc) x 64 x 64\n","            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            # state size. (ndf) x 32 x 32\n","            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(ndf * 2),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            # state size. (ndf*2) x 16 x 16\n","            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(ndf * 4),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            # state size. (ndf*4) x 8 x 8\n","            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(ndf * 8),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            # state size. (ndf*8) x 4 x 4\n","            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n","            nn.Sigmoid()\n","        )\n","\n","    def forward(self, input):\n","        return self.main(input)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"PrJiDEwWvs8y"},"source":["## Define the model and hyperparameters -- Do **NOT** change!\n","GAN training is very sensitive to hyperparameter setting.\n","Here, we provide the set of hyperparameters that the authors in their original implementation. Please do not change any values. Otherwise, we cannot guarantee that your GAN will converge."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"70tdkfIvvs8z","colab":{}},"source":["# Number of training epochs\n","num_epochs = 2\n","# Batch size during training\n","batch_size = 128\n","# Learning rate for optimizers\n","lr = 0.0002\n","# Beta1 hyperparam for Adam optimizers\n","beta1 = 0.5\n","beta2 = 0.999\n","\n","# Setup Adam optimizers for both G and D\n","netD = Discriminator()\n","netG = Generator()\n","optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, beta2))\n","optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, beta2))\n","\n","criterion = torch.nn.BCELoss()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"jRqSRPfLvs82"},"source":["## Train Loop"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"xE-cRXj1vs82","colab":{}},"source":["# Training Loop\n","use_cuda = True\n","device = torch.device('cuda')\n","\n","# Lists to keep track of progress\n","img_list = []\n","D_loss_store = []\n","G_loss_store = []\n","\n","netD = netD.to(device)\n","netG = netG.to(device)\n","\n","dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n","\n","print(\"Starting Training Loop...\")\n","# For each epoch\n","for epoch in range(num_epochs):\n","    G_losses = []\n","    D_losses = []\n","        # For each batch in the dataloader\n","    for i, (images, _) in enumerate(dataloader):\n","\n","        # Train discriminator with real data\n","        mini_batch = images.size()[0]\n","        images_real = images.to(device)\n","        y_real = torch.ones(mini_batch).to(device)\n","        y_fake = torch.zeros(mini_batch).to(device)\n","\n","        # Forward pass real batch through D\n","        d_output_real = netD(images_real).squeeze()\n","        d_loss_real = criterion(d_output_real, y_real)\n","\n","        # Train discriminator with fake data\n","        noise = torch.randn(mini_batch, nz, 1, 1).to(device)\n","        images_fake = netG(noise)\n","\n","        # Forward pass fake batch through D\n","        d_output_fake = netD(images_fake).squeeze()\n","        d_loss_fake = criterion(d_output_fake, y_fake)\n","\n","        # Backprop\n","        d_loss = d_loss_real + d_loss_fake\n","        netD.zero_grad()\n","        d_loss.backward()\n","        optimizerD.step()\n","\n","        # Train the generator\n","        noise = torch.randn(mini_batch, nz, 1, 1).to(device)\n","        images_fake = netG(noise)\n","\n","        d_output_fake = netD(images_fake).squeeze()\n","        g_loss = criterion(d_output_fake, y_real)\n","\n","        # Backprop\n","        netD.zero_grad()\n","        netG.zero_grad()\n","        g_loss.backward()\n","        optimizerG.step()\n","\n","        D_losses.append(d_loss.data)\n","        G_losses.append(g_loss.data)\n","    \n","    D_avg_loss = torch.mean(torch.FloatTensor(D_losses))\n","    G_avg_loss = torch.mean(torch.FloatTensor(G_losses))\n","    \n","    D_loss_store.append(D_avg_loss.data)\n","    G_loss_store.append(G_avg_loss.data)\n","    \n","    print(f'Epoch {epoch+1}/{num_epochs}, D_loss: {D_avg_loss.data}, G_loss: {G_avg_loss.data}')\n","    \n","    if ((epoch == num_epochs-1) and i == len(dataloader) - 1):\n","        with torch.no_grad():\n","            fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n","            fake = netG(fixed_noise).detach().cpu()\n","        img_list.append(vutils.make_grid(fake, padding = 2, normalize=True))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"9kmRAzn7vs9A"},"source":["## Compare real and fake images"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"RPHt9WXRvs9B","colab":{}},"source":["# Grab a batch of real images from the dataloader\n","real_batch = next(iter(dataloader))\n","\n","# Plot the real images\n","plt.figure(figsize=(15,15))\n","plt.subplot(1,2,1)\n","plt.axis(\"off\")\n","plt.title(\"Real Images\")\n","plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=5, normalize=True).cpu(),(1,2,0)))\n","\n","# Plot the fake images from the last epoch\n","plt.subplot(1,2,2)\n","plt.axis(\"off\")\n","plt.title(\"Fake Images\")\n","plt.imshow(np.transpose(img_list[-1],(1,2,0)))\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"B7RpzWLiKMsI","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}