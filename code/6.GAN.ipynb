{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Lab4_GAN.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"qcMu8aQGvs8d"},"source":["## Download necessary libraries "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"rkvnrzXgvs8f","colab":{}},"source":["from __future__ import print_function\n","#%matplotlib inline\n","import argparse\n","import os\n","import zipfile\n","import random\n","import torch\n","import torch.nn as nn\n","import torch.nn.parallel\n","import torch.backends.cudnn as cudnn\n","import torch.optim as optim\n","import torch.utils.data\n","import torchvision.datasets as dset\n","import torchvision.transforms as transforms\n","import torchvision.utils as vutils\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib.animation as animation\n","from IPython.display import HTML"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XqvDb7VucYPi","colab_type":"text"},"source":["## Download celebA Dataset"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"k9t5JVc3wUzJ","colab":{}},"source":["!mkdir data_faces && wget https://s3-us-west-1.amazonaws.com/udacity-dlnfd/datasets/celeba.zip \n","\n","with zipfile.ZipFile(\"celeba.zip\",\"r\") as zip_ref:\n","  zip_ref.extractall(\"data_faces/\")\n","\n","dataDir = 'data_faces/img_align_celeba'\n","img_list = os.listdir(dataDir)\n","print(len(img_list))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"HqTx0go1vs8n","colab":{}},"source":["# Create the dataset\n","dataset = dset.ImageFolder(root='./data_faces',\n","                           transform=transforms.Compose([\n","                               transforms.Resize(64),\n","                               transforms.CenterCrop(64),\n","                               transforms.ToTensor(),\n","                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n","                           ]))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qodthBx7ccEo","colab_type":"text"},"source":["## Useful variable definitions are provided"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"sgLYHm0-vs8j","colab":{}},"source":["# Number of channels in the training images. For color images this is 3\n","nc = 3\n","# Size of z latent vector (i.e. size of generator input)\n","nz = 100\n","# size of feature maps in generator\n","ngf = 64\n","# Size of feature maps in discriminator\n","ndf = 64"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jOfa8BFschT3","colab_type":"text"},"source":["## Implement generator & discriminator"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"zcFdaEZ4vs8t","colab":{}},"source":["class Generator(nn.Module):\n","    def __init__(self):\n","        super(Generator, self).__init__()\n","        \"\"\"\n","        TODO\n","        \"\"\"\n","\n","    def forward(self, input):\n","        return g_out"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"gLwfT-kovs8w","colab":{}},"source":["class Discriminator(nn.Module):\n","    def __init__(self):\n","        super(Discriminator, self).__init__()\n","        \"\"\"\n","        TODO\n","        \"\"\"\n","\n","    def forward(self, input):\n","      \"\"\"\n","      TODO\n","      \"\"\"\n","        return d_out"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"PrJiDEwWvs8y"},"source":["## Define the model and hyperparameters -- Do **NOT** change!\n","GAN training is very sensitive to hyperparameter setting.\n","Here, we provide the set of hyperparameters that the authors in their original implementation. Please do not change any values. Otherwise, we cannot guarantee that your GAN will converge."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"70tdkfIvvs8z","colab":{}},"source":["# Number of training epochs\n","num_epochs = 2\n","# Batch size during training\n","batch_size = 128\n","# Learning rate for optimizers\n","lr = 0.0002\n","# Beta1 hyperparam for Adam optimizers\n","beta1 = 0.5\n","beta2 = 0.999\n","\n","# Establish convention for real and fake labels during training\n","real_label = 1\n","fake_label = 0\n","\n","# Setup Adam optimizers for both G and D\n","netD = Discriminator()\n","netG = Generator()\n","optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, beta2))\n","optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, beta2))\n","\n","criterion = torch.nn.BCELoss()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"jRqSRPfLvs82"},"source":["## Train loop"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"xE-cRXj1vs82","colab":{}},"source":["# Training Loop\n","use_cuda = True\n","device = torch.device('cuda')\n","\n","# Lists to keep track of progress\n","img_list = []\n","D_loss_store = []\n","G_loss_store = []\n","\n","netD = netD.to(device)\n","netG = netG.to(device)\n","\n","dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n","\n","print(\"Starting Training Loop...\")\n","# For each epoch\n","for epoch in range(num_epochs):\n","    G_losses = []\n","    D_losses = []\n","        # For each batch in the dataloader\n","    for i, (images, _) in enumerate(dataloader):\n","\n","        # Train discriminator with real data\n","        \"\"\"TODO\"\"\"\n","\n","\n","        # Forward pass real batch through D\n","        \"\"\"TODO\"\"\"\n","\n","\n","        # Train discriminator with fake data\n","        \"\"\"TODO\"\"\"\n","\n","\n","        # Forward pass fake batch through D\n","        \"\"\"TODO\"\"\"\n","\n","\n","        # Backprop - discriminator\n","        \"\"\"TODO\"\"\"\n","\n","\n","        # Train the generator\n","        \"\"\"TODO\"\"\"\n","\n","\n","        # Backprop - generator\n","        \"\"\"TODO\"\"\"\n","\n","\n","        # Store losses for tracking the progress of G & D\n","        D_losses.append(d_loss.data)\n","        G_losses.append(g_loss.data)\n","    \n","    D_avg_loss = torch.mean(torch.FloatTensor(D_losses))\n","    G_avg_loss = torch.mean(torch.FloatTensor(G_losses))\n","    \n","    D_loss_store.append(D_avg_loss.data)\n","    G_loss_store.append(G_avg_loss.data)\n","    \n","    print(f'Epoch {epoch+1}/{num_epochs}, D_loss: {D_avg_loss.data}, G_loss: {G_avg_loss.data}')\n","    \n","    if ((epoch == num_epochs-1) and i == len(dataloader) - 1):\n","        with torch.no_grad():\n","            fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n","            fake = netG(fixed_noise).detach().cpu()\n","        img_list.append(vutils.make_grid(fake, padding = 2, normalize=True))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"9kmRAzn7vs9A"},"source":["## Compare real and fake images"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"RPHt9WXRvs9B","colab":{}},"source":["# Grab a batch of real images from the dataloader\n","real_batch = next(iter(dataloader))\n","\n","# Plot the real images\n","plt.figure(figsize=(15,15))\n","plt.subplot(1,2,1)\n","plt.axis(\"off\")\n","plt.title(\"Real Images\")\n","plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=5, normalize=True).cpu(),(1,2,0)))\n","\n","# Plot the fake images from the last epoch\n","plt.subplot(1,2,2)\n","plt.axis(\"off\")\n","plt.title(\"Fake Images\")\n","plt.imshow(np.transpose(img_list[-1],(1,2,0)))\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"B7RpzWLiKMsI","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}